
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Polynomial Chaos Expansions</title>
    
    <link rel="stylesheet" href="_static/default.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="_static/sidebar.js"></script>

        <script src="http://sagecell.sagemath.org/static/jquery.min.js"></script>
        <script src="http://sagecell.sagemath.org/static/embedded_sagecell.js"></script>

        <script>sagecell.makeSagecell({inputLocation: ".sage"});</script>

        <style type="text/css">
                .sagecell .CodeMirror-scroll {
                        overflow-y: hidden;
                        overflow-x: auto;
                }
                .sagecell .CodeMirror {
                        height: auto;
                }
        </style>

    
    <link rel="top" title="Chaospy Documentation" href="index.html" />
    <link rel="next" title="Conclusion and Further Work" href="._chaospy005.html" />
    <link rel="prev" title="Modelling Random Variables" href="._chaospy003.html" />
 
  
       <style type="text/css">
         div.admonition {
           background-color: whiteSmoke;
           border: 1px solid #bababa;
         }
       </style>
      </head>
    
  <body role="document">
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="._chaospy005.html" title="Conclusion and Further Work"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="._chaospy003.html" title="Modelling Random Variables"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Chaospy Documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="polynomial-chaos-expansions">
<span id="sec-chaos"></span><h1>Polynomial Chaos Expansions<a class="headerlink" href="#polynomial-chaos-expansions" title="Permalink to this headline">¶</a></h1>
<p>Polynomial chaos expansions represent a collection of methods that can
be considered a subset of polynomial approximation methods, but
particularly designed for uncertainty quantification.  A general
polynomial approximation can be defined as</p>
<div class="math" id="equation-eq_approx_poly">
<span id="eq-eq-approx-poly"></span><span class="eqno">(1)</span>\[         \hat f(\bm x, t, \bm Q) =
         \sum_{n\in I_N} c_n(\bm x, t) \bm\Phi_n(\bm Q) \qquad
         I_N = \{0,\dots,N\},\]</div>
<p>where <span class="math">\(\{c_n\}_{n\in I_N}\)</span> are coefficients (often known as Fourier coefficients)
and <span class="math">\(\{\bm\Phi_n\}_{n\in I_N}\)</span> are polynomials.
If <span class="math">\(\hat f\)</span> is a good approximation of <span class="math">\(f\)</span>, it is possible to
either infer statistical properties of <span class="math">\(\hat f\)</span> analytically
or through cheap numerical computations where <span class="math">\(\hat f\)</span> is used
as a surrogate for <span class="math">\(f\)</span>.</p>
<p>A polynomial chaos expansion is defined as a polynomial approximation,
as in <a href="#equation-eq_approx_poly">(1)</a>, where the polynomials
<span class="math">\(\{\bm\Phi_n\}_{n\in I_N}\)</span> are orthogonal on a custom weighted
function space <span class="math">\(L_Q\)</span>:</p>
<div class="math" id="equation-eq_orthogonal">
<span id="eq-eq-orthogonal"></span><span class="eqno">(2)</span>\[         \inner{\bm\Phi_n,\bm\Phi_m} =
         \E{ \bm\Phi_n(\bm Q) \bm\Phi_m(\bm Q) } =
         \idotsint \bm\Phi_n(\bm q) \bm\Phi_m(\bm q)
             p_{\bm Q}(\bm q) \ud \bm q = 0
         n\neq m.\]</div>
<p>As a side note, it is worth noting that in parallel with polynomial
chaos expansions, there also exists an alternative collocation method
based on multivariate Lagrange polynomials <a class="reference internal" href="._chaospy005.html#ref28" id="id1">[Ref28]</a>.
This method is supported by Dakota and Chaospy, but not Turns.</p>
<p>To generate a polynomial chaos expansion, we must first calculate the
polynomials <span class="math">\(\{\boldsymbol{\Phi}_n\}_{n\in I_N}\)</span> such that the orthogonality
property in <a href="#equation-eq_orthogonal">(2)</a> is satisfied.  This will be the topic
of the section <a class="reference internal" href="#sec-orthogonal"><span class="std std-ref">Orthogonal Polynomials Construction</span></a> In the section <a class="reference internal" href="#sec-spectral"><span class="std std-ref">Calculating Coefficients</span></a> we show
how to estimate the coefficients <span class="math">\(\{c_n\}_{n\in I_N}\)</span>.  Last, in
the section <a class="reference internal" href="#sec-descriptive"><span class="std std-ref">Descriptive Tools</span></a>, tools used to quantify uncertainty in
polynomial chaos expansions will be discussed.</p>
<div class="section" id="orthogonal-polynomials-construction">
<span id="sec-orthogonal"></span><h2>Orthogonal Polynomials Construction<a class="headerlink" href="#orthogonal-polynomials-construction" title="Permalink to this headline">¶</a></h2>
<p>From <a href="#equation-eq_orthogonal">(2)</a> it follows that the orthogonality property
is not in general transferable between distributions, since a new set
of polynomials has to be constructed for each <span class="math">\(p_{\bm Q}\)</span>.  The
easiest approach to construct orthogonal polynomials is to identify
the probability density <span class="math">\(p_{\bm Q}\)</span> in the so-called Askey-Wilson
scheme <a class="reference internal" href="._chaospy005.html#ref29" id="id2">[Ref29]</a>.  The polynomials can then be picked
from a list, or be built from analytical components.  The continuous
distributions supported in the scheme include the standard normal,
gamma, beta, and uniform distributions respectively through the
Hermite, Laguerre, Jacobi, and Legendre polynomial expansion.  All the
three mentioned software toolboxes support these expansions.</p>
<p>Moving beyond the standard collection of the Askey-Wilson scheme, it
is possible to create custom orthogonal polynomials, both analytically
and numerically.  Unfortunately, most methods involving finite
precision arithmetics are ill-posed, making a numerical approach quite
a challenge <a class="reference internal" href="._chaospy005.html#ref30" id="id3">[Ref30]</a>.  This section explores
the various approaches for constructing polynomial expansions.  A full
list of methods is found in the table below.  It shows that Dakota,
Turns and Chaospy support 4, 3 and 5 orthogonalisation methods,
respectively.</p>
<table border="1" class="docutils">
<colgroup>
<col width="63%" />
<col width="12%" />
<col width="10%" />
<col width="14%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><strong>Orthogonalization Method</strong></th>
<th class="head">Dakota</th>
<th class="head">Turns</th>
<th class="head">Chaospy</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>Askey-Wilson Scheme <a class="reference internal" href="._chaospy005.html#ref29" id="id4">[Ref29]</a></td>
<td>yes</td>
<td>yes</td>
<td>yes</td>
</tr>
<tr class="row-odd"><td>Bertran recursion <a class="reference internal" href="._chaospy005.html#ref31" id="id5">[Ref31]</a></td>
<td>no</td>
<td>no</td>
<td>yes</td>
</tr>
<tr class="row-even"><td>Cholesky Decomposition <a class="reference internal" href="._chaospy005.html#ref14" id="id6">[Ref14]</a></td>
<td>no</td>
<td>no</td>
<td>yes</td>
</tr>
<tr class="row-odd"><td>Discretized Stieltjes <a class="reference internal" href="._chaospy005.html#ref32" id="id7">[Ref32]</a></td>
<td>yes</td>
<td>no</td>
<td>yes</td>
</tr>
<tr class="row-even"><td>Modified Chebyshev <a class="reference internal" href="._chaospy005.html#ref32" id="id8">[Ref32]</a></td>
<td>yes</td>
<td>yes</td>
<td>no</td>
</tr>
<tr class="row-odd"><td>Modified Gram-Schmidt <a class="reference internal" href="._chaospy005.html#ref32" id="id9">[Ref32]</a></td>
<td>yes</td>
<td>yes</td>
<td>yes</td>
</tr>
</tbody>
</table>
<p>Looking beyond an analytical approach, the most popular method for
constructing orthogonal polynomials is the discretized Stieltjes
procedure <a class="reference internal" href="._chaospy005.html#ref33" id="id10">[Ref33]</a>.  As far as the authors know,
it is the only truly numerically stable method for orthogonal
polynomial construction.  It is based upon one-dimensional recursion
coefficients that are estimated using numerical integration.
Unfortunately, the method is only applicable in the multivariate case
if the components of <span class="math">\(p_{\bm Q}\)</span> are stochastically independent.</p>
<div class="section" id="generalized-polynomial-chaos-expansions">
<h3>Generalized Polynomial Chaos Expansions<a class="headerlink" href="#generalized-polynomial-chaos-expansions" title="Permalink to this headline">¶</a></h3>
<p>One approach to model densities with stochastically dependent
components numerically, is to reformulate the uncertainty problem as a
set of independent components through generalised polynomial chaos
expansion <a class="reference internal" href="._chaospy005.html#ref34" id="id11">[Ref34]</a>.  As described in detail in
the section <a class="reference internal" href="._chaospy003.html#sec-rosenblatt"><span class="std std-ref">Rosenblatt Transformation</span></a>, a Rosenblatt transformation allows for
the mapping between any domain and the unit hypercube <span class="math">\([0,1]^D\)</span>.  With
a double transformation we can reformulate the response function <span class="math">\(f\)</span>
as</p>
<div class="math">
\[\begin{split}f(\bm x, t, \bm Q) =
f(\bm x, t, T_{\bm Q}^{-1}(T_{\bm R}(\bm R))) &amp;\approx
\hat f(\bm x, t, \bm R) =
\sum_{n\in I_N} c_n(\bm x, t)\bm \Phi_n(\bm R),\end{split}\]</div>
<p>where <span class="math">\(\bm R\)</span> is any random variable drawn from <span class="math">\(p_{\bm R}\)</span>, which
for simplicity is chosen to consists of independent components.
Also, <span class="math">\(\{\bm\Phi_n\}_{n\in I_N}\)</span>
is constructed to be orthogonal with respect to <span class="math">\(L_{\bm R}\)</span>, not
<span class="math">\(L_{\bm Q}\)</span>.
In any case, <span class="math">\(\bm R\)</span> is either selected from the Askey-Wilson
scheme, or calculated using the discretized Stieltjes procedure.
We remark that the accuracy of the approximation deteriorate if the
transformation composition <span class="math">\(T_{\bm Q}^{-1}\circ T_{\bm R}\)</span> is not
smooth <a class="reference internal" href="._chaospy005.html#ref34" id="id12">[Ref34]</a>.</p>
<p>Dakota, Turns, and Chaospy all support generalized polynomial chaos
expansions for independent stochastic variables and the Normal/Nataf
copula listed in the table in the section <a class="reference internal" href="._chaospy003.html#sec-copulas"><span class="std std-ref">Copulas</span></a>.  Since Chaospy
has the Rosenblatt transformation underlying the computational
framework, generalized polynomial chaos expansions are in fact
available for all densities.</p>
</div>
<div class="section" id="the-direct-multivariate-approach">
<h3>The Direct Multivariate Approach<a class="headerlink" href="#the-direct-multivariate-approach" title="Permalink to this headline">¶</a></h3>
<p>Given that both the density <span class="math">\(p_{\bm Q}\)</span> has stochastically dependent
components, and the transformation composition <span class="math">\(T^{-1}_{\bm Q}\circ
T_{\bm R}\)</span> is not smooth, it is still possible to generate orthogonal
polynomials numerically.  As noted above, most methods are numerically
unstable, and the accuracy in the orthogonality can deteriorate with
polynomial order, but the methods can still be useful
<a class="reference internal" href="._chaospy005.html#ref14" id="id13">[Ref14]</a>.  In the table in the section <a class="reference internal" href="#sec-orthogonal"><span class="std std-ref">Orthogonal Polynomials Construction</span></a>, only Chaospy&#8217;s implementation of Bertran&#8217;s
recursion method <a class="reference internal" href="._chaospy005.html#ref31" id="id14">[Ref31]</a>, Cholesky decomposition
<a class="reference internal" href="._chaospy005.html#ref35" id="id15">[Ref35]</a> and modified Gram-Schmidt
orthogonalization <a class="reference internal" href="._chaospy005.html#ref32" id="id16">[Ref32]</a> support construction
of orthogonal polynomials for multivariate dependent densities
directly.</p>
</div>
<div class="section" id="custom-polynomial-expansions">
<h3>Custom Polynomial Expansions<a class="headerlink" href="#custom-polynomial-expansions" title="Permalink to this headline">¶</a></h3>
<p>In the most extreme cases, an automated numerical method is
insufficient.  Instead, a polynomial expansion has to be constructed
manually.  User-defined expansions can be created conveniently, as
demonstrated in the next example involving a second-order Hermite
polynomial expansion, orthogonal with respect to the normal density
<a class="reference internal" href="._chaospy005.html#ref29" id="id17">[Ref29]</a>:</p>
<div class="math">
\[\left\{\bm\Phi_n\right\}_{n\in I_6} =
\left\{ 1, Q_0, Q_1, Q_0^2-1, Q_0Q_1, Q_1^2-1 \right\}\]</div>
<p>The relevant Chaospy code for creating this polynomial expansion looks like</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">q0</span><span class="p">,</span> <span class="n">q1</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">variable</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phi</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Poly</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="n">q0</span><span class="p">,</span> <span class="n">q1</span><span class="p">,</span> <span class="n">q0</span><span class="o">**</span><span class="mi">2</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">q0</span><span class="o">*</span><span class="n">q1</span><span class="p">,</span> <span class="n">q1</span><span class="o">**</span><span class="mi">2</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">phi</span>
<span class="go">[1, q0, q1, q0^2-1, q0q1, -1+q1^2]</span>
</pre></div>
</div>
<p>Chaospy contains a collection of tools to manipulate and create
polynomials, see the table below.</p>
<table border="1" class="docutils">
<colgroup>
<col width="30%" />
<col width="70%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><strong>Function</strong></th>
<th class="head"><strong>Description</strong></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><code class="docutils literal"><span class="pre">all</span></code></td>
<td>Test all coefficients for non-zero</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">any</span></code></td>
<td>Test any coefficients for non-zero</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">around</span></code></td>
<td>Round to a given decimal</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">asfloat</span></code></td>
<td>Set coefficients type as float</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">asint</span></code></td>
<td>Set coefficient type as int</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">basis</span></code></td>
<td>Create monomial basis</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">cumprod</span></code></td>
<td>Cumulative product</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">cumsum</span></code></td>
<td>Cumulative sum</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">cutoff</span></code></td>
<td>Truncate polynomial order</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">decompose</span></code></td>
<td>Convert from series to sequence</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">diag</span></code></td>
<td>Construct or extract diagonal</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">differential</span></code></td>
<td>Differential operator</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">dot</span></code></td>
<td>Dot-product</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">flatten</span></code></td>
<td>Flatten an array</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">gradient</span></code></td>
<td>Gradient (or Jacobian) operator</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">hessian</span></code></td>
<td>Hessian operator</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">inner</span></code></td>
<td>Inner product</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">mean</span></code></td>
<td>Average</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">order</span></code></td>
<td>Extract polynomial order</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">outer</span></code></td>
<td>Outer product</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">prod</span></code></td>
<td>Product</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">repeat</span></code></td>
<td>Repeat polynomials</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">reshape</span></code></td>
<td>Reshape axes</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">roll</span></code></td>
<td>Roll polynomials</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">rollaxis</span></code></td>
<td>Roll axis</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">rolldim</span></code></td>
<td>Roll the dimension</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">std</span></code></td>
<td>Empirical standard deviation</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">substitute</span></code></td>
<td>Variable substitution</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">sum</span></code></td>
<td>Sum along an axis</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">swapaxes</span></code></td>
<td>Interchange two axes</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">swapdim</span></code></td>
<td>Swap the dimensions</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">trace</span></code></td>
<td>Sum along the diagonal</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">transpose</span></code></td>
<td>Transpose the coefficients</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">tril</span></code></td>
<td>Extract lower triangle of coefficients</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">tricu</span></code></td>
<td>Extract cross-diagonal upper triangle</td>
</tr>
<tr class="row-odd"><td><code class="docutils literal"><span class="pre">var</span></code></td>
<td>Empirical variance</td>
</tr>
<tr class="row-even"><td><code class="docutils literal"><span class="pre">variable</span></code></td>
<td>Simple polynomial constructor</td>
</tr>
</tbody>
</table>
<p>One thing worth noting is that polynomial chaos expansions suffers
from the curse of dimensionality: The number of terms grows
exponentially with the number of dimensions <a class="reference internal" href="._chaospy005.html#ref36" id="id18">[Ref36]</a>.  As a
result, Chaospy does not support neither high dimensional nor infinite
dimensional problems (random fields).  One approach to address such
problems with polynomial chaos expansion is to first reduce the number
of dimension through techniques like Karhunen-Loeve expansions
<a class="reference internal" href="._chaospy005.html#ref37" id="id19">[Ref37]</a>.  If software implementations of such
methods can be provided, the user can easily extend Chaospy to high
and infinite dimensional problems.</p>
<p>Chaospy includes operators such as the expectation operator <span class="math">\(\mathbb
E\)</span>.  This is a helpful tool to ensure that the constructed polynomials
are orthogonal, as defined in <a href="#equation-eq_orthogonal">(2)</a>.  To verify that
two elements in <code class="docutils literal"><span class="pre">phi</span></code> are indeed orthogonal under the standard
bivariate normal distribution, one writes</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">dist</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">J</span><span class="p">(</span><span class="n">cp</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">cp</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">cp</span><span class="o">.</span><span class="n">E</span><span class="p">(</span><span class="n">phi</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">dist</span><span class="p">)</span>
<span class="go">0.0</span>
</pre></div>
</div>
<p>More details of operators used to perform uncertainty analysis
are given in the section <a class="reference internal" href="#sec-descriptive"><span class="std std-ref">Descriptive Tools</span></a>.</p>
<p>color{black}</p>
</div>
</div>
<div class="section" id="calculating-coefficients">
<span id="sec-spectral"></span><h2>Calculating Coefficients<a class="headerlink" href="#calculating-coefficients" title="Permalink to this headline">¶</a></h2>
<p>There are several methodologies for estimating the coefficients
<span class="math">\(\{c_n\}_{n\in I_N}\)</span>, typically categorized either as non-intrusive or
intrusive, where non-intrusive means that the computational procedures
only requires evaluation of <span class="math">\(f\)</span> (i.e., software for <span class="math">\(f\)</span> can be reused
as a black box). Intrusive methods need to incorporate information
about the underlying forward model in the computation of the
coefficients. In case of forward models based on differential
equations, one performs a Galerkin formulation for the coefficients in
probability space, leading effectively to a <span class="math">\(D\)</span>-dimensional
differential equation problem in this space
<a class="reference internal" href="._chaospy005.html#ref38" id="id20">[Ref38]</a>.  Back et al. <a class="reference internal" href="._chaospy005.html#ref39" id="id21">[Ref39]</a>
demonstrated that the computational cost of such an intrusive Galerkin
method in some cases was higher than some non-intrusive methods.  None
of the three toolboxes discussed in this paper have support for
intrusive methods.</p>
<p>Within the realm of non-intrusive methods, there are in principle two
viable methodologies available: pseudo-spectral projection
<a class="reference internal" href="._chaospy005.html#ref40" id="id22">[Ref40]</a> and the point collocation method
<a class="reference internal" href="._chaospy005.html#ref41" id="id23">[Ref41]</a>.  The former applies a numerical
integration scheme to estimate Fourier coefficients, while the latter
solves a linear system arising from a statistical regression
formulation.  Dakota and Chaospy support both methodologies, while
Turns only supports point collocation.  We shall now discuss the
practical, generic implementation of these two methods in Chaospy.</p>
</div>
<div class="section" id="integration-methods">
<h2>Integration Methods<a class="headerlink" href="#integration-methods" title="Permalink to this headline">¶</a></h2>
<p>The pseudo-spectral projection method is based on a standard least
squares minimization in the weighted function space <span class="math">\(L_{\bm Q}\)</span>.
Since the polynomials are orthogonal in this space, the associated
linear system is diagonal, which allows a closed-form expression for
the Fourier coefficients. The expression involves high-dimensional
integrals in <span class="math">\(L_{\bm Q}\)</span>. Numerical integration is then required,</p>
<div class="math" id="equation-eq_quadrature">
<span id="eq-eq-quadrature"></span><span class="eqno">(3)</span>\[         c_n = \frac{\E{Y \bm\Phi_n}}{\E{\bm\Phi_n^2}} =
         \frac{1}{\E{\bm\Phi_n^2}} \idotsint p_{\bm Q}(\bm q)
         f(\bm x, t, \bm q) \bm\Phi_n(\bm q)\ud\bm q\]</div>
<div class="math">
\[\notag
  \approx \frac{1}{\E{\bm\Phi_n^2}}
  \sum_{k\in I_K} w_k p_{\bm Q}(\bm q_k)
  f(\bm x, t, \bm q_k)
  \bm\Phi_n(\bm q_k)
  I_K = \{0,\dots,K-1\},\]</div>
<p>where <span class="math">\(w_k\)</span> are weights and <span class="math">\(\bm q_k\)</span> nodes in a quadrature scheme.
Note that <span class="math">\(f\)</span> is only evaluated for the nodes <span class="math">\(\boldsymbol{q}_k\)</span>, and these
evaluations can be made once. Thereafter, one can experiment with the
polynomial order since any <span class="math">\(c_n\)</span> depends on the same evaluations of <span class="math">\(f\)</span>.</p>
<p>The table below shows the various quadrature schemes offered by Dakota
and Chaospy (recall that Turns does not support pseudo-spectral
projection).</p>
<table border="1" class="docutils">
<colgroup>
<col width="67%" />
<col width="11%" />
<col width="9%" />
<col width="13%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><strong>Node and Weight Generators</strong></th>
<th class="head">Dakota</th>
<th class="head">Turns</th>
<th class="head">Chaospy</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>Clenshaw-Curtis quadrature <a class="reference internal" href="._chaospy005.html#ref42" id="id24">[Ref42]</a></td>
<td>yes</td>
<td>no</td>
<td>yes</td>
</tr>
<tr class="row-odd"><td>Cubature rules <a class="reference internal" href="._chaospy005.html#ref43" id="id25">[Ref43]</a></td>
<td>yes</td>
<td>no</td>
<td>no</td>
</tr>
<tr class="row-even"><td>Gauss-Legendre quadrature <a class="reference internal" href="._chaospy005.html#ref44" id="id26">[Ref44]</a></td>
<td>yes</td>
<td>no</td>
<td>yes</td>
</tr>
<tr class="row-odd"><td>Gauss-Patterson quadrature <a class="reference internal" href="._chaospy005.html#ref45" id="id27">[Ref45]</a></td>
<td>yes</td>
<td>no</td>
<td>yes</td>
</tr>
<tr class="row-even"><td>Genz-Keister quadrature <a class="reference internal" href="._chaospy005.html#ref46" id="id28">[Ref46]</a></td>
<td>yes</td>
<td>no</td>
<td>yes</td>
</tr>
<tr class="row-odd"><td>Leja quadrature <a class="reference internal" href="._chaospy005.html#ref47" id="id29">[Ref47]</a></td>
<td>no</td>
<td>no</td>
<td>yes</td>
</tr>
<tr class="row-even"><td>Monte Carlo integration <a class="reference internal" href="._chaospy005.html#ref01" id="id30">[Ref01]</a></td>
<td>yes</td>
<td>no</td>
<td>yes</td>
</tr>
<tr class="row-odd"><td>Optimal Gaussian quadrature <a class="reference internal" href="._chaospy005.html#ref44" id="id31">[Ref44]</a></td>
<td>yes</td>
<td>no</td>
<td>yes</td>
</tr>
</tbody>
</table>
<p>All techniques for generating nodes and weights in Chaospy are
available through the <code class="docutils literal"><span class="pre">cp.generate_quadrature</span></code> function.  Suppose we
want to generate optimal Gaussian quadrature nodes for the normal
distribution. We then write</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">nodes</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">generate_quadrature</span><span class="p">(</span>
<span class="gp">... </span>            <span class="mi">3</span><span class="p">,</span> <span class="n">cp</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">rule</span><span class="o">=</span><span class="s">&quot;Gaussian&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">nodes</span>
<span class="go">[[-2.33441422 -0.74196378  0.74196378  2.33441422]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">weights</span>
<span class="go">[ 0.04587585  0.45412415  0.45412415  0.04587585]</span>
</pre></div>
</div>
<p>Most quadrature schemes are designed for univariate problems.  To
extend a univariate scheme to the multivariate case, integration rules
along each axis can be combined using a tensor product.
Unfortunately, such a product suffers from the curse of dimensionality
and becomes a very costly integration procedure for large <span class="math">\(D\)</span>.  In
higher-dimensional problems one can replace the full tensor product by
a Smolyak sparse grid <a class="reference internal" href="._chaospy005.html#ref48" id="id32">[Ref48]</a>.  The method works
by taking multiple lower order tensor product rules and joining them
together.  If the rule is nested, i.e., the same samples found at a
low order are also included at higher order, the number of evaluations
can be further reduced.  Another feature is to add anisotropy such
that some dimensions are sampled more than others
<a class="reference internal" href="._chaospy005.html#ref49" id="id33">[Ref49]</a>.  In addition to the tensor product
rules, there are a few native multivariate cubature rules that allow
for low order multivariate integration <a class="reference internal" href="._chaospy005.html#ref43" id="id34">[Ref43]</a>.
Both Dakota and Chaospy also support the Smolyak sparse grid and
anisotropy.</p>
<p>Chaospy has support for construction of custom integration rules
defined by the user.  The <code class="docutils literal"><span class="pre">cp.rule_generator</span></code> function can be used to
join a list of univariate rules using tensor grid or Smolyak sparse
grid.  For example, consider the trapezoid rule:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">trapezoid</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
<span class="gp">... </span>   <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">... </span>   <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">n</span>
<span class="gp">... </span>   <span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*=</span> <span class="mf">0.5</span><span class="p">;</span> <span class="n">W</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*=</span> <span class="mf">0.5</span>
<span class="gp">... </span>   <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">W</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodes</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">trapezoid</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">nodes</span>
<span class="go">[ 0.   0.5  1. ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">weights</span>
<span class="go">[ 0.25  0.5   0.25]</span>
</pre></div>
</div>
<p>The <code class="docutils literal"><span class="pre">cp.rule_generator</span></code> function takes positional arguments, each
representing a univariate rule.  To generate a rule for the
multivariate case, with the same one-dimensional rule along two axes,
we do the following:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">mvtrapezoid</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">rule_generator</span><span class="p">(</span><span class="n">trapezoid</span><span class="p">,</span> <span class="n">trapezoid</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nodes</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">mvtrapezoid</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">nodes</span>
<span class="go">[[ 0.   0.5  1.   0.   0.   1. ]</span>
<span class="go"> [ 0.   0.   0.   0.5  1.   1. ]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">weights</span>
<span class="go">[ 0.     0.25   0.125  0.25   0.125  0.25 ]</span>
</pre></div>
</div>
<p>Software for constructing and executing a general-purpose integration
scheme is useful for several computational components in uncertainty
quantification.  For example, in the section <a class="reference internal" href="#sec-orthogonal"><span class="std std-ref">Orthogonal Polynomials Construction</span></a> when
constructing orthogonal polynomials using raw statistical moments, or
calculating discretized Stieltjes&#8217; recurrence coefficients, numerical
integration is relevant.  Like the <code class="docutils literal"><span class="pre">ppf</span></code> function noted in the section <a class="reference internal" href="._chaospy003.html#sec-variable"><span class="std std-ref">Constructing Distributions</span></a>, the moments and recurrence coefficients can be
added directly into each distribution.  However, when these are not
available, Chaospy will automatically estimate missing information by
quadrature rules, using the <code class="docutils literal"><span class="pre">cp.generate_quadrature</span></code> function
described above.</p>
<p>To compute the Fourier coefficients and the polynomial chaos
expansion, we use the <code class="docutils literal"><span class="pre">cp.fit_quadrature</span></code> function.  It takes four
arguments: the set of orthogonal polynomials, quadrature nodes,
quadrature weights, and the user&#8217;s function for evaluating the forward
model (to be executed at the quadrature nodes).  Note that in the case
of the discretized Stieltjes method discussed in the section <a class="reference internal" href="#sec-orthogonal"><span class="std std-ref">Orthogonal Polynomials Construction</span></a>, the nominator <span class="math">\(\E{\bm\Phi_n^2}\)</span> in
<a href="#equation-eq_quadrature">(3)</a> can be calculated more accurately using
recurrence coefficients <a class="reference internal" href="._chaospy005.html#ref32" id="id35">[Ref32]</a>.  Special
numerical features like this can be added by including optional
arguments in <code class="docutils literal"><span class="pre">cp.fit_quadrature</span></code>.</p>
</div>
<div class="section" id="point-collocation">
<span id="sec-ptcolloc"></span><h2>Point Collocation<a class="headerlink" href="#point-collocation" title="Permalink to this headline">¶</a></h2>
<p>The other non-intrusive approach to estimate the coefficients
<span class="math">\(\{c_k\}_{k\in I_K}\)</span> is the point collocation method.  One way of
formulating the method is to require the polynomial expansion to equal
the model evaluations at a set of collocation nodes <span class="math">\(\{\bm q_k\}_{k\in
I_K}\)</span>, resulting in an over-determined set of linear equations for the
Fourier coefficients:</p>
<div class="math" id="equation-eq_pcm">
<span id="eq-eq-pcm"></span><span class="eqno">(4)</span>\[         \begin{bmatrix}
             \Phi_0(\boldsymbol{q}_0)  \cdots  \Phi_N(\boldsymbol{q}_0)\]</div>
<div class="math">
\[\vdots    \vdots\]</div>
<div class="math">
\[    \Phi_0(\boldsymbol{q}_{K-1})  \cdots  \Phi_N(\boldsymbol{q}_{K-1})
\end{bmatrix}
\begin{bmatrix}
    c_0\]</div>
<div class="math">
\[\vdots\]</div>
<div class="math">
\[c_N
  \end{bmatrix} =
  \begin{bmatrix}
      f(\boldsymbol{q}_0)\]</div>
<div class="math">
\[\vdots\]</div>
<div class="math">
\[    f(\boldsymbol{q}_{K-1})
\end{bmatrix},\]</div>
<p>Unlike pseudo spectral projection, the locations of the collocation
nodes are not required to follow any integration rule.  Hosder
<a class="reference internal" href="._chaospy005.html#ref41" id="id36">[Ref41]</a> showed that the solution using Hammersley
samples from quasi-Monte Carlo samples resulted in more stable results
than using conventional pseudo-random samples.  In other words, well
placed collocation nodes might increase the accuracy.  In Chaospy
these collocation nodes can be selected from integration rules or from
pseudo-random samples from Monte Carlo simulation, as discussed in
the section <a class="reference internal" href="._chaospy003.html#sec-monte-carlo"><span class="std std-ref">Variance Reduction Techniques</span></a>.  In addition, the software accepts user
defined strategies for choosing the sampling points.  Turns also
allows for user-defined points, while Dakota has its predefined
strategies.</p>
<p>The obvious way to solve the over-determined system in <a href="#equation-eq_pcm">(4)</a>
is to use least squares minimization, which resembles the standard
statistical linear regression approach of fitting a polynomial to a
set of data points.  However, from a numerical point of view, this
might not be the best strategy.  If the numerical stability of the
solution is low, it might be prudent to use Tikhonov regularization
<a class="reference internal" href="._chaospy005.html#ref50" id="id37">[Ref50]</a>, or if the problem is so large that the number
of coefficients is very high, it might be useful to force some of the
coefficients to be zero through least angle regression
<a class="reference internal" href="._chaospy005.html#ref51" id="id38">[Ref51]</a>.  Being able to run and compare alternative
methods is important in many problems to see if numerical stability is
a potential problem. The table below lists the regression
methods offered by Dakota, Turns, and Chaospy.</p>
<table border="1" class="docutils">
<colgroup>
<col width="72%" />
<col width="9%" />
<col width="8%" />
<col width="11%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><strong>Regression Schemes</strong></th>
<th class="head">Dakota</th>
<th class="head">Turns</th>
<th class="head">Chaospy</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>Basis Pursuit <a class="reference internal" href="._chaospy005.html#ref52" id="id39">[Ref52]</a></td>
<td>yes</td>
<td>no</td>
<td>no</td>
</tr>
<tr class="row-odd"><td>Bayesian Auto. Relevance Determination <a class="reference internal" href="._chaospy005.html#ref53" id="id40">[Ref53]</a></td>
<td>no</td>
<td>no</td>
<td>yes</td>
</tr>
<tr class="row-even"><td>Bayesian ridge <a class="reference internal" href="._chaospy005.html#ref54" id="id41">[Ref54]</a></td>
<td>no</td>
<td>no</td>
<td>yes</td>
</tr>
<tr class="row-odd"><td>Elastic Net <a class="reference internal" href="._chaospy005.html#ref55" id="id42">[Ref55]</a></td>
<td>yes</td>
<td>no</td>
<td>yes</td>
</tr>
<tr class="row-even"><td>Forward Stagewise <a class="reference internal" href="._chaospy005.html#ref56" id="id43">[Ref56]</a></td>
<td>no</td>
<td>yes</td>
<td>no</td>
</tr>
<tr class="row-odd"><td>Least Absolute Shrinkage and Selection <a class="reference internal" href="._chaospy005.html#ref51" id="id44">[Ref51]</a></td>
<td>yes</td>
<td>yes</td>
<td>yes</td>
</tr>
<tr class="row-even"><td>Least Angle and Shrinkage with AIC/BIC <a class="reference internal" href="._chaospy005.html#ref57" id="id45">[Ref57]</a></td>
<td>no</td>
<td>no</td>
<td>yes</td>
</tr>
<tr class="row-odd"><td>Least Squares Minimization</td>
<td>yes</td>
<td>yes</td>
<td>yes</td>
</tr>
<tr class="row-even"><td>Orthogonal matching pursuit <a class="reference internal" href="._chaospy005.html#ref58" id="id46">[Ref58]</a></td>
<td>yes</td>
<td>no</td>
<td>yes</td>
</tr>
<tr class="row-odd"><td>Singular Value Decomposition</td>
<td>no</td>
<td>yes</td>
<td>no</td>
</tr>
<tr class="row-even"><td>Tikhonov Regularization <a class="reference internal" href="._chaospy005.html#ref50" id="id47">[Ref50]</a></td>
<td>no</td>
<td>no</td>
<td>yes</td>
</tr>
</tbody>
</table>
<p>Generating a polynomial chaos expansion using linear
regression is done using Chaospy&#8217;s <code class="docutils literal"><span class="pre">cp.fit_regression</span></code> function.
It takes the same arguments as <code class="docutils literal"><span class="pre">cp.fit_quadrature</span></code>, except that
quadrature weights are omitted, and optional arguments
define the rule used to optimize <a href="#equation-eq_pcm">(4)</a>.</p>
</div>
<div class="section" id="model-evaluations">
<h2>Model Evaluations<a class="headerlink" href="#model-evaluations" title="Permalink to this headline">¶</a></h2>
<p>Irrespectively of the method used to estimate the coefficients <span class="math">\(c_k\)</span>,
the user is left with the job to evaluate the forward model (response
function) <span class="math">\(f\)</span>, which is normally by far the most computing-intensive
part in uncertainty quantification.  Chaospy does not impose any
restriction on the simulation code used to compute the forward
model. The only requirement is that the user can provide an array of
values of <span class="math">\(f\)</span> at the quadrature or collocation nodes.  Chaospy users
will usually wrap any complex simulation code for <span class="math">\(f\)</span> in a Python
function <code class="docutils literal"><span class="pre">f(q)</span></code>, where <code class="docutils literal"><span class="pre">q</span></code> is a node in probability space (i.e., <code class="docutils literal"><span class="pre">q</span></code>
contains values of the uncertain parameters in the problem).  For
example, for pseudo-spectral projection, samples of <span class="math">\(f\)</span> can be created
as</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span><span class="p">(</span><span class="n">node</span><span class="p">)</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span><span class="o">.</span><span class="n">T</span><span class="p">]</span>
</pre></div>
</div>
<p>or perhaps done in parallel if <span class="math">\(f\)</span> is time consuming to evaluate:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">multiprocessing</span> <span class="kn">as</span> <span class="nn">mp</span>
<span class="n">pool</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">Pool</span><span class="p">(</span><span class="n">mp</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">())</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">nodes</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</pre></div>
</div>
<p>The evaluation of all the <span class="math">\(f\)</span> values can also be done in parallel with
MPI in a distributed way on a cluster using the Python module like
<code class="docutils literal"><span class="pre">mpi4py</span></code>.  Both Dakota and Turns support parallel evaluation of <span class="math">\(f\)</span>
values, but the feature is embeded into the code, potentially limiting
the customization options of the parallelization.</p>
</div>
<div class="section" id="extension-of-polynomial-expansions">
<h2>Extension of polynomial expansions<a class="headerlink" href="#extension-of-polynomial-expansions" title="Permalink to this headline">¶</a></h2>
<p>There is much literature that extends on the theory of polynomial
chaos expansion <a class="reference internal" href="._chaospy005.html#ref36" id="id48">[Ref36]</a>.  For example, Isukapalli showed
that the accuracy of a polynomial expansion could be increased by
using partial derivatives of the model response
<a class="reference internal" href="._chaospy005.html#ref59" id="id49">[Ref59]</a>.  This theory is only directly
supported by Dakota.  In Turns and Chaospy the support is indirect by
allowing the user to add the feature manually.</p>
<p>To be able to incorporate partial derivatives of the response, the
partial derivative of the polynomial expansion must be available as
well.  In both Turns and Chaospy, the derivative of a polynomial can
be generated easily.  This derivative can then be added to the
expansion, allowing us to incorporate Isukapalli&#8217;s theory in practice.
This is just an example on how manipulation of the polynomial
expansions and model approximations can overcome the lack of support
for a particular feature from the literature.</p>
<p>To be able to support many current and possible future extensions of
polynomial chaos, a large collection of tools for manipulating
polynomials must be available.  In Dakota, no such tools exist from a
user perspective.  In Turns, there is support for some arithmetic
operators in addition to the derivative.  In Chaospy, however, the
polynomial generated for the model response is of the same type as the
polynomials generated in the sections <a class="reference internal" href="#sec-orthogonal"><span class="std std-ref">Orthogonal Polynomials Construction</span></a> and
<a class="reference internal" href="#sec-spectral"><span class="std std-ref">Calculating Coefficients</span></a>, and the rich set of manipulations of polynomials is
then available for <span class="math">\(\hat f\)</span> as well.</p>
<p>Beyond the analytical tools for statistical analysis of <span class="math">\(\hat f\)</span>,
either from the toolbox or custom ones by the user, there are many
statistical metrics that cannot easily be expressed as simple
closed-form formulas.  Such metrics include confidence intervals,
sensitivity indices, p-values in hypothesis testing, to mention a few.
In those scenarios, it makes sense to perform a secondary uncertainty
analysis through Monte Carlo simulation.  Evaluating the approximation
<span class="math">\(\hat f\)</span> is normally computationally much cheaper than evaluating the
full forward model <span class="math">\(f\)</span>, thus allowing a large number of Monte Carlo
samples within a cheap computational budget.  This type of secondary
simulations are done automatically in the background in Dakota and
Turns, while Chaospy does not feature automated tools for secondary
Monte Carlo simulation.  Instead, Chaospy allows for simple and
computationally cheap generation of pseudo-random samples, as
described in the section <a class="reference internal" href="._chaospy003.html#sec-monte-carlo"><span class="std std-ref">Variance Reduction Techniques</span></a>, such that the user can
easily put together a tailored Monte Carlo simulation to meet the
needs at hand.  Within a few lines of Python code, the samples can be
analyzed with the standard Numpy and the Scipy libraries
<a class="reference internal" href="._chaospy005.html#ref60" id="id50">[Ref60]</a> or with more specialized statistical libraries
like Pandas <a class="reference internal" href="._chaospy005.html#ref09" id="id51">[Ref09]</a>, Scikit-learn
<a class="reference internal" href="._chaospy005.html#ref61" id="id52">[Ref61]</a>, Scikit-statsmodel
<a class="reference internal" href="._chaospy005.html#ref62" id="id53">[Ref62]</a>, and Python&#8217;s interface to the rich R
environment for statistical computing.  For example, for the specific
<span class="math">\(\hat f\)</span> function illustrated above, the following code computes a 90
percent confidence interval, based on <span class="math">\(10^5\)</span> pseudo-random samples and
Numpy&#8217;s functionality for finding percentiles in discrete data:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">q_samples</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span> <span class="o">=</span> <span class="n">f_approx</span><span class="p">(</span><span class="o">*</span><span class="n">q_samples</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p05</span><span class="p">,</span> <span class="n">p95</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">95</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">p05</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
<span class="go">[ 1.         1.0000004  1.0000016]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">p95</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
<span class="go">[ 1.          1.00038886  1.00155544]</span>
</pre></div>
</div>
<p>Since the type of statistical analysis of <span class="math">\(\hat f\)</span> often strongly
depends on the physical problem at hand, we believe that the ability
to quickly compose custom solutions by putting together basic building
blocks is very useful in uncertainty quantification. This is yet
another example of the need for a package with a strong focus on easy
customization.</p>
</div>
<div class="section" id="descriptive-tools">
<span id="sec-descriptive"></span><h2>Descriptive Tools<a class="headerlink" href="#descriptive-tools" title="Permalink to this headline">¶</a></h2>
<p>The last step in uncertainty quantification based on polynomial chaos
expansions is to quantify the uncertainty.  In polynomial chaos
expansion this is done by using the uncertainty in the model
approximation <code class="docutils literal"><span class="pre">f_approx</span></code> as a substiute for the uncertainty in the
model <span class="math">\(f\)</span>.</p>
<p>For the most popular statistical metrics, like mean, variance,
correlation, a polynomial chaos expansion allows for analytical
analysis, which is easy to calculate and has high accuracy.  This
property is reflected in all the three toolboxes.  To calculate the
expected value, variance and correlation of a simple (here univariate)
polynomial approximation <code class="docutils literal"><span class="pre">f_approx</span></code>, with a normally distributed
<span class="math">\(\xi_0\)</span> variable, we can with Chaospy write</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">f_approx</span> <span class="o">=</span> <span class="n">fit_quadrature</span><span class="p">(</span><span class="n">orth</span><span class="p">,</span> <span class="n">nodes</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">samples</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">f_approx</span>
<span class="go">[q0, q0^2, q0^3]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dist</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">E</span><span class="p">(</span><span class="n">f_approx</span><span class="p">,</span> <span class="n">dist</span><span class="p">)</span>
<span class="go">[ 0.  1.  0.]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">Var</span><span class="p">(</span><span class="n">f_approx</span><span class="p">,</span> <span class="n">dist</span><span class="p">)</span>
<span class="go">[  1.   2.  15.]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">Corr</span><span class="p">(</span><span class="n">f_approx</span><span class="p">,</span> <span class="n">dist</span><span class="p">)</span>
<span class="go">[[ 1.          0.          0.77459667]</span>
<span class="go"> [ 0.          1.          0.        ]</span>
<span class="go"> [ 0.77459667  0.          1.        ]]</span>
</pre></div>
</div>
<p>A list of supported analytical metrics is listed in the table below.</p>
<table border="1" class="docutils">
<colgroup>
<col width="56%" />
<col width="15%" />
<col width="12%" />
<col width="17%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><strong>Method</strong></th>
<th class="head">Dakota</th>
<th class="head">Turns</th>
<th class="head">Chaospy</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>Covariance/Correlation</td>
<td>yes</td>
<td>yes</td>
<td>yes</td>
</tr>
<tr class="row-odd"><td>Expected value</td>
<td>yes</td>
<td>yes</td>
<td>yes</td>
</tr>
<tr class="row-even"><td>Conditional expectation</td>
<td>no</td>
<td>no</td>
<td>yes</td>
</tr>
<tr class="row-odd"><td>Kurtosis</td>
<td>yes</td>
<td>yes</td>
<td>yes</td>
</tr>
<tr class="row-even"><td>Sensitivity index</td>
<td>yes</td>
<td>yes</td>
<td>yes</td>
</tr>
<tr class="row-odd"><td>Skewness</td>
<td>yes</td>
<td>yes</td>
<td>yes</td>
</tr>
<tr class="row-even"><td>Variance</td>
<td>yes</td>
<td>yes</td>
<td>yes</td>
</tr>
</tbody>
</table>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <center>
            <p class="logo"><a href="http://cbc.simula.no/" title="Go to Center for Biomedical Computing">
              <img class="logo" src="_static/cbc_logo.png" alt="Logo"/>
            </a></p>
            </center>
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Polynomial Chaos Expansions</a><ul>
<li><a class="reference internal" href="#orthogonal-polynomials-construction">Orthogonal Polynomials Construction</a><ul>
<li><a class="reference internal" href="#generalized-polynomial-chaos-expansions">Generalized Polynomial Chaos Expansions</a></li>
<li><a class="reference internal" href="#the-direct-multivariate-approach">The Direct Multivariate Approach</a></li>
<li><a class="reference internal" href="#custom-polynomial-expansions">Custom Polynomial Expansions</a></li>
</ul>
</li>
<li><a class="reference internal" href="#calculating-coefficients">Calculating Coefficients</a></li>
<li><a class="reference internal" href="#integration-methods">Integration Methods</a></li>
<li><a class="reference internal" href="#point-collocation">Point Collocation</a></li>
<li><a class="reference internal" href="#model-evaluations">Model Evaluations</a></li>
<li><a class="reference internal" href="#extension-of-polynomial-expansions">Extension of polynomial expansions</a></li>
<li><a class="reference internal" href="#descriptive-tools">Descriptive Tools</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="._chaospy003.html"
                        title="previous chapter">Modelling Random Variables</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="._chaospy005.html"
                        title="next chapter">Conclusion and Further Work</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/._chaospy004.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="._chaospy005.html" title="Conclusion and Further Work"
             >next</a> |</li>
        <li class="right" >
          <a href="._chaospy003.html" title="Modelling Random Variables"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Chaospy Documentation</a> &raquo;</li> 
      </ul>
    </div>
<div class="wrapper">
  <div class="footer">
    <a href="http://cbc.simula.no"><img src="_static/cbc_banner.png" width="100%"><a>
    <br />
    <br />
      &copy;2015, Jonathan Feinberg, Hans Petter Langtangen. Released under CC Attribution-NonCommercial 4.0 license.
  </div>
</div>

  </body>
</html>